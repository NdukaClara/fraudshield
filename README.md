# ğŸ›¡ï¸ FraudShield â€” Real-Time Fraud Detection Pipeline

**FraudShield** is a real-time data engineering project designed to simulate how financial institutions handle and detect suspicious transactions in live data streams.

Built with **Kafka**, **PostgreSQL**, and **Streamlit**, the project demonstrates how streaming data pipelines can power real-time fraud analytics â€” from ingestion to visualization.

---

## ğŸ§  Project Overview

FraudShield explores how organizations that consume real-time data, especially banks and payment processors, manage transaction flows and identify anomalous patterns as data moves through the pipeline.

The system simulates:

- A **data producer** continuously generating synthetic financial transactions.  
- A **Kafka broker** that streams those transactions in real time.  
- A **consumer and loader service** that ingests and stores data in PostgreSQL.  
- A **Streamlit dashboard** for live analytics, fraud detection trends, and transaction summaries.

This pipeline mirrors how real-world systems detect fraud signals â€” whether through thresholds, metadata patterns, or customer behavior â€” as data flows from ingestion to analytics.

---

## ğŸ§© Architecture Overview

### Core Components

| **Layer**              | **Component**          | **Description**                                                                 |
|------------------------|------------------------|---------------------------------------------------------------------------------|
| Data Generation        | **Producer**           | Uses Faker to simulate financial transactions (customer, merchant, card type, status, etc.) |
| Message Queue          | **Apache Kafka**       | Streams real-time transactions between producer and consumer                   |
| Data Storage           | **PostgreSQL**         | Stores raw and processed transactions for querying and dashboard analysis       |
| Monitoring UI          | **Streamlit Dashboard**| Displays aggregated metrics, suspicious activity, and transaction insights      |
| Management Tools       | **pgAdmin**            | Provides visual database management and query interface                         |

---


## ğŸ“Š End-to-End Flow
```
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚   Data Producer    â”‚
                â”‚ (Kafka Producer)   â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚      Kafka         â”‚
                â”‚ (Event Stream)     â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚  Simple Consumer   â”‚
                â”‚ (Message Reader)   â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚   Data Loader      â”‚
                â”‚ (Writes to DB)     â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚     Postgres       â”‚
                â”‚ (Data Storage)     â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚     Dashboard      â”‚
                â”‚ (Stream Analytics) â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

```

## ğŸ”„ Data Flow

### 1ï¸âƒ£ Transaction Simulation  
A **Python-based producer** continuously generates transaction records with fields like amount, merchant, card type, and timestamps.  
Each record is published to a Kafka topic (`transactions`).

---

### 2ï¸âƒ£ Real-Time Ingestion  
The **Kafka consumer** listens to the same topic and streams incoming messages.  
As transactions arrive, theyâ€™re processed and pushed into **PostgreSQL** through the **data loader service**.

---

### 3ï¸âƒ£ Persistent Storage  
Each transaction is stored in the `transactions` table with columns like:

- `transaction_id`  
- `customer_id`  
- `merchant`  
- `amount`  
- `currency`  
- `card_type`  
- `status`  
- `is_suspicious`  
- `timestamp`

---

### 4ï¸âƒ£ Analytics Dashboard  
The **Streamlit dashboard** connects directly to the Postgres database and provides:

- Transaction summaries and trends  
- Suspicious customer leaderboards  
- Real-time fraud insights  
- Monthly and daily transaction aggregations  

---

## âš™ï¸ Key Features

âœ… **Real-Time Streaming:** Transaction data flows from producer â†’ Kafka â†’ Postgres continuously.  
âœ… **Dynamic Fraud Tagging:** Randomized flags for `is_suspicious` simulate real fraud scenarios.  
âœ… **Fully Containerized Environment:** All components (Kafka, Postgres, pgAdmin) run inside Docker.  
âœ… **Data Persistence:** PostgreSQL stores each transaction for historical and analytical insights.  
âœ… **Interactive Dashboard:** Built with Streamlit and Plotly for rich, real-time visualizations.  
âœ… **Modular Design:** Independent Python modules for producing, consuming, loading, and analyzing data.  
âœ… **Scalable Architecture:** Ready for future integration with Spark Structured Streaming and ML models.

---

## ğŸ§± Project Structure

```
fraudshield/
â”‚
â”œâ”€â”€ producer/
â”‚   â”œâ”€â”€ producer.py               # Generates and streams transaction data
â”‚   â””â”€â”€ requirements.txt          # Python dependencies for producer.py    
â”‚
â”œâ”€â”€ consumer/           
â”‚   â”œâ”€â”€ simple_consumer.py        # Reads messages from Kafka topic
â”‚   â”œâ”€â”€ requirements.txt          # Python dependencies for consumer.py   
â”‚   â””â”€â”€ data_loader.py            # Loads consumed data into Postgres               
â”‚
â”œâ”€â”€ dashboard/
â”‚   â””â”€â”€ app.py                    # Streamlit dashboard for analytics
â”‚
â”œâ”€â”€ db/
â”‚   â””â”€â”€ init.sql                  # Database schema for transactions table
â”‚
â”œâ”€â”€ docker/
â”‚   â””â”€â”€ docker-compose.yml        # Container setup for Kafka, Postgres, pgAdmin
â”‚
â”œâ”€â”€ .env                          # Environment variables for container services
â”‚
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ setup_instructions.md     # Detailed project setup and run instructions
â”‚
â””â”€â”€ README.md                     # Project overview (this file)
```
---

## ğŸš€ Planned Extensions

Future updates will introduce:

### ğŸ”¹ Spark Structured Streaming
To replace the basic Kafka consumer with a distributed stream processing engine capable of large-scale data ingestion, transformation, and real-time fraud analytics.

### ğŸ”¹ Machine Learning Model Integration
A predictive fraud detection layer trained on historical transaction data to identify high-risk patterns, such as anomalous transaction frequency, unusual time-of-day activity, or suspicious location behavior. The model will generate fraud risk scores for each transaction and flag potential threats in real time.

### ğŸ”¹ Full Dockerized Deployment
The current setup already containerizes Kafka, ZooKeeper, and Postgres. Future updates will extend Docker integration to include the producer, consumer, and Streamlit dashboard, enabling a single-command startup for the entire pipeline.


---

## ğŸ“˜ Setup and Deployment

All detailed setup steps â€” including project structure, Docker setup, environment variables, and running each component â€” are documented here:

ğŸ“‚ **[docs/setup_instructions.md](./docs/setup_instructions.md)**

---

## ğŸ§¾ License

This project is publicly available for learning and demonstration purposes only.  
All rights are reserved â€” reuse, modification, or redistribution of any part of this codebase is **not permitted** without explicit permission from the author.


---

## âœ¨ Author

**Clara Nduka**  
_Data & Software Engineer_  
ğŸ“« [ndukaclara@gmail.com](mailto:ndukaclara@gmail.com)  
ğŸ’¼ [linkedin.com/in/clara-nduka](https://www.linkedin.com/in/clara-nduka)

